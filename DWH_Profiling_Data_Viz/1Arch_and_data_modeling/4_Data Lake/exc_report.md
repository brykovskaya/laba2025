## üîÅ –£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ Data LakeüîÅ
#### –¶–µ–ª—å: –ù–∞—É—á–∏—Ç—å—Å—è –∑–∞–≥—Ä—É–∂–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤ Data Lake.

–ó–∞–¥–∞–Ω–∏–µ:

–í—ã–±–µ—Ä–∏—Ç–µ –æ–±–ª–∞—á–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä, Amazon S3, Google Cloud Storage –∏–ª–∏ Azure Blob Storage.<br>
—É –Ω–∞—Å –µ—Å—Ç—å —Å–≤–æ–µ –º–∏–Ω–∏ –æ–±–ª–∞–∫–æ –∏ "–ª—É–∂–∞" –¥–ª—è –∫—É—Ä—Å–∞ <br>
–û–±–ª–∞–∫–æ - AWS CLI –≤ Yandex Object Storage (–∫—Ä–µ–¥—ã)

–°–æ–∑–¥–∞–π—Ç–µ –±–∞–∫–µ—Ç (–∏–ª–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä) –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö.<br>
–°–∫–∞—á–∞–π—Ç–µ –æ—Ç–∫—Ä—ã—Ç—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, Titanic dataset –∏–ª–∏ Iris dataset) –≤ —Ñ–æ—Ä–º–∞—Ç–µ CSV –∏–ª–∏ JSON.<br>
–ó–∞–≥—Ä—É–∑–∏—Ç–µ —ç—Ç–æ—Ç —Ñ–∞–π–ª –≤ –≤–∞—à –±–∞–∫–µ—Ç/–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä.<br>
–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —Ñ–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω, –∏ –∑–∞–ø–∏—à–∏—Ç–µ –µ–≥–æ –ø—É—Ç—å.<br>

### ‚òëÔ∏è —Ä–µ—à–µ–Ω–∏–µ
–∫–æ–¥ –∫–æ—Ç–æ—Ä—ã–π —Å—Ä–∞–±–æ—Ç–∞–ª
```
aws --version
aws configure
configure set endpoint_url https://storage.yandexcloud.net/
aws s3 ls s3://laboratory-ba
aws s3 cp data.csv s3://laboratory-ba/data.csv
```
—Ä–∞–Ω–µ–µ –±—ã–ª —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω aws 
—Ç–µ–ø–µ—Ä—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –≤—ã–ø–æ–ª–Ω—è—é —à–∞–≥–∏ - —Å–º–æ—Ç—Ä—é –∫–∞–∫–∞—è –≤–µ—Ä—Å–∏—è AWS —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ 
![](../images/16.png)<br>
–ù–∞—Å—Ç–∞–∏–≤–∞–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ AWS CLI –≤ Yandex Object S<br>
–≤–≤–æ–∂—É –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é —ç–Ω–¥–ø–æ–∏–Ω—Ç.

–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –±—É–¥—É—Ç –∑–∞–ø–∏—Å–∞–Ω—ã –¥–≤–∞ —Ñ–∞–π–ª–∞ –≤ –ø–∞–ø–∫—É –°:\–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏\<–∏–º—è —Ç–≤–æ–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è>\.aws  . –ø–∞–ø–∫–∞ –ø–æ—è–≤–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏. –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫–∏–µ –µ—Å—Ç—å —Ñ–∞–π–ª—ã.

![](../images/24.png)<br>

![](../images/25.png)<br>
–î–ª—è —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ –ø—Ä–∏–Ω—è—Ç–æ —Ä–µ—à–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–º–µ—é—â–∏–π—Å—è –±–∞–∫–µ—Ç laboratory-ba —Ç.–∫. –¥–æ—Å—Ç—É–ø–∞ –∫ –µ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—é –Ω–µ—Ç.<br>
–ó–∞–≥—Ä—É–∂–∞—é –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö `game_logs.csv` –æ –ª–æ–≥–∞—Ö –∏–≥—Ä—ã –∑–∞ 130 –ª–µ—Ç –∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞—é –µ–≥–æ –∫–∞–∫ `game_logs_brykovskaya.csv` –∏ –∑–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫ —Ñ–∞–π–ª –±—ã–ª –∑–∞–ø–∏—Å–∞–Ω –≤ –æ–±–ª–∞–∫–æ
![](../images/254.png)<br>

## üîÅ –£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ 2: –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Ç–∞–ª–æ–≥–∞ –¥–∞–Ω–Ω—ã—Ö
### –¶–µ–ª—å: –ù–∞—É—á–∏—Ç—å—Å—è —É–ø—Ä–∞–≤–ª—è—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –≤ Data Lake.
–ó–∞–¥–∞–Ω–∏–µ:<br>
–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏, —Ç–∞–∫–æ–π –∫–∞–∫ Apache Hive –∏–ª–∏ AWS Glue.
1. –°–æ–∑–¥–∞–π—Ç–µ —Ç–∞–±–ª–∏—Ü—É –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞—à–µ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è 1.
1. –û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ —Å—Ö–µ–º—É —Ç–∞–±–ª–∏—Ü—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–º–µ–Ω–∞ —Å—Ç–æ–ª–±—Ü–æ–≤, —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö).
1. –£–∫–∞–∂–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö –∏ –æ–ø–∏—Å–∞–Ω–∏–µ.
1. –ó–∞–ø–æ–ª–Ω–∏—Ç–µ —Ç–∞–±–ª–∏—Ü—É –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã–º–∏ –æ –≤–∞—à–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö, –≤–∫–ª—é—á–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–º, –æ—Ç–∫—É–¥–∞ –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –ø–æ–ª—É—á–µ–Ω—ã, –∏ –∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä–µ.

### –†–µ—à–µ–Ω–∏–µ

–ü–æ–¥–Ω–∏–º–∞—é –∫–æ—Ç–Ω–µ–π–Ω–µ—Ä —Å Hive.

–ó–∞–ø—É—Å—Ç–∏—Ç–µ Apache Hive –≤–Ω—É—Ç—Ä–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ docker –≤ –ø—Å–µ–≤–¥–æ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ, —á—Ç–æ–±—ã –æ–±–µ—Å–ø–µ—á–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –±—ã—Å—Ç—Ä—ã–π –∑–∞–ø—É—Å–∫ / –æ—Ç–ª–∞–¥–∫—É / –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—É—é —Å—Ä–µ–¥—É –¥–ª—è Hive

#### STEP 1: Pull the image
Pull the image from DockerHub: https://hub.docker.com/r/apache/hive/tags. Here are the latest images:
4.0.0-beta-1  3.1.3

`docker pull apache/hive:4.0.0-alpha-2`

![](../images/10_.png)<br>
#### STEP 2: Export the Hive version
`export HIVE_VERSION=4.0.0-alpha-2`

![](../images/11_.png)<br>

![](../images/26.png)<br>

Usage
```
HiveServer2 web
Accessed on browser at http://localhost:10002/
```
Beeline:
```
  docker exec -it hiveserver2 beeline -u 'jdbc:hive2://hiveserver2:10000/'
  # If beeline is installed on host machine, HiveServer2 can be simply reached via:
  beeline -u 'jdbc:hive2://localhost:10000/'
```
some queries:
   - show tables;
   - create table hive_example(a string, b int) partitioned by(c int);
   - alter table hive_example add partition(c=1);
   - insert into hive_example partition(c=1) values('a', 1), ('a', 2),('b',3);
   - select count(distinct a) from hive_example;
   - select sum(b) from hive_example;

–ó–∞–ø—É—Å–∫ Apache Hive –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ:
```
cmd
    C:\Users\79181>docker run -d -p 10000:10000 -p 10002:10002 -e SERVICE_NAME=hiveserver2 --name hive4 apache/hive:4.0.1
```

–î–∞–ª–µ–µ –≤ –¥—Ä—É–≥–æ–º –æ–∫–Ω–µ cmd:
    
```
cmd
C:\Users\79181>docker exec -it hive4 beeline -u 'jdbc:hive2://localhost:10000/'
```

- –°–æ–∑–¥–∞–π—Ç–µ —Ç–∞–±–ª–∏—Ü—É –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞—à–µ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è 1. –î–ª—è —É–¥–æ–±—Å—Ç–≤–∞ —Å–æ–∑–¥–∞–º –¥–ª—è —É–∂–µ –Ω–∞—Ö–æ–¥—è—â–µ–≥–æ—Å—è –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö iris

```
cmd
0: jdbc:hive2://localhost:10000/> CREATE TABLE IF NOT EXISTS iris_metadata
(column_name STRING, data_type STRING, description STRING)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' STORED AS TEXTFILE;
```

–û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ —Å—Ö–µ–º—É —Ç–∞–±–ª–∏—Ü—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–º–µ–Ω–∞ —Å—Ç–æ–ª–±—Ü–æ–≤, —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö).

–£–∫–∞–∂–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö –∏ –æ–ø–∏—Å–∞–Ω–∏–µ.

–ó–∞–ø–æ–ª–Ω–∏—Ç–µ —Ç–∞–±–ª–∏—Ü—É –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã–º–∏ –æ –≤–∞—à–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö, –≤–∫–ª—é—á–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–º, –æ—Ç–∫—É–¥–∞ –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –ø–æ–ª—É—á–µ–Ω—ã, –∏ –∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä–µ.

```
0: jdbc:hive2://localhost:10000/> INSERT INTO iris_metadata VALUES
('sepal_length', 'DOUBLE', 'Length of the sepal in cm'),
('sepal_width', 'DOUBLE', 'Width of the sepal in cm'),
('petal_length', 'DOUBLE', 'Length of the petal in cm'),
('petal_width', 'DOUBLE', 'Width of the petal in cm'),
('species', 'STRING', 'Species name (setosa, versicolor, virginica)');
```

–ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∞–±–ª–∏—Ü—É:

```
0: jdbc:hive2://localhost:10000/> SELECT * FROM iris_metadata;
```
–†–µ–∑—É–ª—å—Ç–∞—Ç:
![](../images/27.png)

## üîÅ –£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ 3: –û—á–∏—Å—Ç–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
#### –¶–µ–ª—å: –ù–∞—É—á–∏—Ç—å—Å—è –æ—á–∏—â–∞—Ç—å –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.
–ó–∞–¥–∞–Ω–∏–µ:

- –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤–∞—à–µ–≥–æ Data Lake (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É—è Apache Spark –∏–ª–∏ Pandas –≤ Python).
    ```python
    import pandas as pd 
    import boto3
    from io import StringIO
    import numpy as np

    session =boto3.session.Session()
    s3 = session.client(
        service_name ='s3',
        endpoint_url ='https://storage.yandexcloud.net/',
        aws_access_key_id ='YCAJEwnMU9buPdj6Uk3NV5LmG',
        aws_secret_access_key ='YCPQy22uGBgPb-_pUgHRFx09fnfF-MapLWG2ojQx')

    bucket = 'laboratory-ba'
    file_name='mz_iris.csv'

    response =s3.get_object(Bucket=bucket,Key=file_name)
    data =response['Body'].read().decode('utf-8')
    df =pd.read_csv(StringIO(data),index_col=0)
    ```

- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏ –≤—ã–±—Ä–æ—Å–æ–≤.
- –í—ã–ø–æ–ª–Ω–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö:
    - –ó–∞–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –º–µ–¥–∏–∞–Ω–æ–π –∏–ª–∏ —Å—Ä–µ–¥–Ω–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º).

    - –£–¥–∞–ª–∏—Ç–µ –∏–ª–∏ –∏—Å–ø—Ä–∞–≤—å—Ç–µ –≤—ã–±—Ä–æ—Å—ã.

    - –ü—Ä–µ–æ–±—Ä–∞–∑—É–π—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ —á–∏—Å–ª–æ–≤—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É—è one-hot encoding).

    ```python
    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()
    for column in df.columns:
        if df[column].dtype == 'float64' or df[column].dtype == 'int64':
            df[column] = df[column].fillna(df[column].median())
    print(df.dtypes)
    for col in numeric_cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        df = df[(df[col] >= (Q1 - 1.5 * IQR)) & (df[col] <= (Q3 + 1.5 * IQR))]
    ```

- –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –æ—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ–±—Ä–∞—Ç–Ω–æ –≤ Data Lake.

    ```python
    csv_buffer =StringIO()
    df.to_csv(csv_buffer, index =False)
    s3.put_object(Bucket=bucket,Key ='mz_iris_clean.csv', Body = csv_buffer.getvalue())
    ```

–ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ Data Lake:

![](../images/28.png)<br>

## üîÅ –£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ 4: –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ ETL-–ø—Ä–æ—Ü–µ—Å—Å–∞
#### –¶–µ–ª—å: –ù–∞—É—á–∏—Ç—å—Å—è —Å–æ–∑–¥–∞–≤–∞—Ç—å ETL-–ø—Ä–æ—Ü–µ—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö. –ó–∞–¥–∞–Ω–∏–µ:
–ù–∞–ø–∏—à–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç –Ω–∞ Python –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Apache NiFi –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è ETL-–ø—Ä–æ—Ü–µ—Å—Å–∞.
-E (Extract): –ò–∑–≤–ª–µ–∫–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤–∞—à–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, CSV –∏–ª–∏ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö).

-T (Transform): –ü—Ä–∏–º–µ–Ω–∏—Ç–µ –æ—á–∏—Å—Ç–∫—É –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –≤—ã–ø–æ–ª–Ω–∏–ª–∏ –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–º —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–∏.

-L (Load): –ó–∞–≥—Ä—É–∑–∏—Ç–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ–±—Ä–∞—Ç–Ω–æ –≤ Data Lake.

–ó–∞–ø—É—Å—Ç–∏—Ç–µ ETL-–ø—Ä–æ—Ü–µ—Å—Å –∏ —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ.

[iris_etl.ipynb](../files/iris_etl.ipynb)
–£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä—É–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–µ (—Å–º. –ø—Ä–µ–¥—ã–¥—É—â–µ–µ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ)

## üîÅ –£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ 5: –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –≤ Data Lake

#### –¶–µ–ª—å: –ù–∞—É—á–∏—Ç—å—Å—è –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ, —Ö—Ä–∞–Ω—è—â–∏–µ—Å—è –≤ Data Lake. –ó–∞–¥–∞–Ω–∏–µ:
–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Apache Spark –∏–ª–∏ SQL-–∑–∞–ø—Ä–æ—Å—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á–µ—Ä–µ–∑ AWS Athena) –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–∞—à–µ–≥–æ –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö.

–í—ã–ø–æ–ª–Ω–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ –∑–∞–ø—Ä–æ—Å—ã:
 - –ü–æ–¥—Å—á–∏—Ç–∞–π—Ç–µ –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π.
 - –ù–∞–π–¥–∏—Ç–µ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤–æ–∑—Ä–∞—Å—Ç, —Ü–µ–Ω–∞).
 - –ü–æ–¥—Å—á–∏—Ç–∞–π—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ–ª, –∫–ª–∞—Å—Å).
 - –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –≤ –æ—Ç—á–µ—Ç–µ –∏–ª–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏.

#### –†–ï–®–ï–ù–ò–ï

[pyspark_analyze.ipynb](../files/pyspark_analyze.ipynb)
```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, avg, countDistinct

# –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é Spark
spark = SparkSession.builder.appName("IrisAnalysis").getOrCreate()

# –ó–∞–≥—Ä—É–∑–∏–º –¥–∞–Ω–Ω—ã–µ –∏–∑ CSV —Ñ–∞–π–ª–∞
df = spark.read.csv("mz_iris_clean.csv", header=True, inferSchema=True)
df = df.drop("Id")
# –ü–æ–∫–∞–∂–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
df.show(5)

total_records = df.count()
print(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {total_records}")

# –°–ø–∏—Å–æ–∫ —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
numerical_columns = [col for col, dtype in df.dtypes if dtype in ('int', 'double')]

# –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
average_values = df.select([avg(col).alias(col) for col in numerical_columns]).show()

# –°–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
categorical_columns = [col for col, dtype in df.dtypes if dtype == 'string']

# –ü–æ–¥—Å—á–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
for column in categorical_columns:
    distinct_count = df.select(column).distinct().count()
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ —Å—Ç–æ–ª–±—Ü–µ {column}: {distinct_count}")

import matplotlib.pyplot as plt
import pandas as pd

# –ü–µ—Ä–µ–≤–æ–¥–∏–º –¥–∞–Ω–Ω—ã–µ Spark DataFrame –≤ Pandas –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ —Ä–∞–±–æ—Ç—ã —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π
df_pandas = df.toPandas()

# –°—Ç—Ä–æ–∏–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–∏—Å–ª–æ–≤–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞
numerical_columns = [col for col, dtype in df.dtypes if dtype in ('int', 'double')]
df_pandas[numerical_columns].hist(bins=10, figsize=(10, 6))
plt.suptitle("–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤")
plt.show()
```

–†–µ–∑—É–ª—å—Ç–∞—Ç:

![](../images/29.png)<br>


## üîÅ –£–ø—Ä–∞–∂–Ω–µ–Ω–∏–µ 6: –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å—é –¥–∞–Ω–Ω—ã—Ö
#### –¶–µ–ª—å: –ù–∞—É—á–∏—Ç—å—Å—è —É–ø—Ä–∞–≤–ª—è—Ç—å –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å—é –¥–∞–Ω–Ω—ã—Ö –≤ Data Lake.
–ó–∞–¥–∞–Ω–∏–µ:

- –û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ, –∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –≤ –≤–∞—à–µ–º Data Lake —è–≤–ª—è—é—Ç—Å—è –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º–∏ –∏–ª–∏ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º–∏.

#### –†–ï–®–ï–ù–ò–ï
–í —É—Å–ª–æ–≤–∏—è—Ö –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –æ—Ç–∫—Ä—ã—Ç—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –∏ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –í —Ä–µ–∞–ª—å–Ω—ã—Ö –∂–µ –ø—Ä–æ–µ–∫—Ç–∞—Ö —ç—Ç–æ –º–æ–≥–ª–∏ –±—ã—Ç—å –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç–æ–≤, –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ —Ç. –¥. 

–° –¥–∞—Ç–∞—Å–µ—Ç–æ–º iris.csv–ø–µ—Ä–¥—Å—Ç–∞–≤–∏–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –≤ –∫–æ–ª–æ–Ω–∫–µ species –±—É–¥—É—Ç "—á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º–∏". –∞ –∏–º–µ–Ω–Ω–æ –≤–∏–¥ —Ä–∞—Å—Ç–µ–Ω–∏—è (species) —è–≤–ª—è–µ—Ç—Å—è –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π, –∫–æ—Ç–æ—Ä—É—é –Ω—É–∂–Ω–æ –∑–∞—â–∏—Ç–∏—Ç—å.

–î–ª—è —ç—Ç–æ–≥–æ 
1. –ù–∞—Å—Ç—Ä–æ–∏–º –∫–æ–Ω—Ç—Ä–æ–ª—å –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–∞–Ω–Ω—ã–º:
–°–æ–∑–¥–∞–¥–∏–º –≥—Ä—É–ø–ø—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —É—Ä–æ–≤–Ω—è–º–∏ –¥–æ—Å—Ç—É–ø–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—ã, –∞–Ω–∞–ª–∏—Ç–∏–∫–∏, –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã).
 - –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—ã: –î–æ—Å—Ç—É–ø –∫–æ –≤—Å–µ–º –¥–∞–Ω–Ω—ã–º.
 - –ê–Ω–∞–ª–∏—Ç–∏–∫–∏: –î–æ—Å—Ç—É–ø —Ç–æ–ª—å–∫–æ –∫ —á–∏—Å–ª–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, sepal_length, sepal_width, petal_length, petal_width).
 - –û–ø–µ—Ä–∞—Ç–æ—Ä—ã: –î–æ—Å—Ç—É–ø –∫ –±–∞–∑–æ–≤—ã–º —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–º –¥–∞–Ω–Ω—ã–º –∏–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –∞–≥—Ä–µ–≥–∞—Ü–∏–∏.

–í —Ä–µ–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö —ç—Ç–æ –æ–±—ã—á–Ω–æ –¥–µ–ª–∞–µ—Ç—Å—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –≤ Data Lake (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å AWS Lake Formation, Apache Ranger –∏–ª–∏ Azure Synapse).

2. –ù–∞—Å—Ç—Ä–æ–∏–º –ø–æ–ª–∏—Ç–∏–∫–∏ –¥–æ—Å—Ç—É–ø–∞, —á—Ç–æ–±—ã –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º –¥–∞–Ω–Ω—ã–º —Ç–æ–ª—å–∫–æ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏–ª–∏ –≥—Ä—É–ø–ø.
 - –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø –∫–æ –≤—Å–µ–º –¥–∞–Ω–Ω—ã–º.
 - –ê–Ω–∞–ª–∏—Ç–∏–∫ –º–æ–∂–µ—Ç –≤–∏–¥–µ—Ç—å —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –Ω–µ –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º –¥–∞–Ω–Ω—ã–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–æ–ª–æ–Ω–∫–∞ species).
 - –û–ø–µ—Ä–∞—Ç–æ—Ä –º–æ–∂–µ—Ç –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–ª—å–∫–æ —Å–≤–æ–¥–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏.

3. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏, —á—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ç–æ–ª—å–∫–æ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –º–æ–≥—É—Ç –ø–æ–ª—É—á–∞—Ç—å –¥–æ—Å—Ç—É–ø –∫ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º –¥–∞–Ω–Ω—ã–º.

–î–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏, –º–æ–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ:
 - –ê–Ω–∞–ª–∏—Ç–∏–∫ –Ω–µ –≤–∏–¥–∏—Ç —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–æ–ª–æ–Ω–∫—É species.
 - –û–ø–µ—Ä–∞—Ç–æ—Ä –≤–∏–¥–∏—Ç —Ç–æ–ª—å–∫–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É, –∞ –Ω–µ –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.